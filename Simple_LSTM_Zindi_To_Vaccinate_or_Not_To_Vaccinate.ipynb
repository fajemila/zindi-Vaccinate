{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Simple LSTM Zindi To Vaccinate or Not To Vaccinate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fajemila/zindi-Vaccinate/blob/main/Simple_LSTM_Zindi_To_Vaccinate_or_Not_To_Vaccinate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCfw18SqC8ZZ"
      },
      "source": [
        "In this Notebook we'll be developing a machine learning model to assess if a Twitter post related to vaccinations is positive, neutral, or negative. This solution could help governments and other public health actors monitor public sentiment towards COVID-19 vaccinations and help improve public health policy, vaccine communication strategies, and vaccination programs across the world.\n",
        "We will start very simple to understand the general concepts whilst not really caring about good results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQBhhR4cEJiM"
      },
      "source": [
        "# Download Data\r\n",
        "on zindi page, right click on Train.csv and click inspect , auth_token and url should be visible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB9d0XCxDEZg"
      },
      "source": [
        "import requests\r\n",
        "import requests, zipfile\r\n",
        "#the url and auth_value from the website \r\n",
        "url1 = \"https://api.zindi.africa/v1/competitions/to-vaccinate-or-not-to-vaccinate-its-not-a-question/files/Train.csv\"\r\n",
        "url2 = \"https://api.zindi.africa/v1/competitions/to-vaccinate-or-not-to-vaccinate-its-not-a-question/files/Test.csv\"\r\n",
        "\r\n",
        "myobj = {'auth_token': '########################'}\r\n",
        "\r\n",
        "x = requests.post(url1, data = myobj,stream=True)\r\n",
        "y = requests.post(url2, data = myobj,stream=True)\r\n",
        "\r\n",
        "target_path1 = 'Train.csv'\r\n",
        "target_path2 = 'Test.csv'\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ixczTLDMnJ"
      },
      "source": [
        "handle = open(target_path1, \"wb\")\r\n",
        "for chunk in x.iter_content(chunk_size=512):\r\n",
        "    if chunk:  # filter out keep-alive new chunks\r\n",
        "        handle.write(chunk)\r\n",
        "handle.close()\r\n",
        "handle = open(target_path2, \"wb\")\r\n",
        "for chunk in y.iter_content(chunk_size=512):\r\n",
        "    if chunk:  # filter out keep-alive new chunks\r\n",
        "        handle.write(chunk)\r\n",
        "handle.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2VAhbbCEQ37"
      },
      "source": [
        "# Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvaJbquuC8Zg",
        "outputId": "b8eb2a10-955d-493f-d6f5-4b1a246c2048"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import time \n",
        "import re\n",
        "# Natural Language Tool Kit \n",
        "import nltk  \n",
        "nltk.download('stopwords') \n",
        "from nltk.corpus import stopwords "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W4SHzA8C8Zi"
      },
      "source": [
        "## 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbQ2u6RjC8Zi"
      },
      "source": [
        "train = pd.read_csv(\"Train.csv\")\n",
        "test = pd.read_csv(\"Test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "d4xif2KcC8Zj",
        "outputId": "137ba856-714e-4931-adb5-2fcc8f7beacb"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>safe_text</th>\n",
              "      <th>label</th>\n",
              "      <th>agreement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CL1KWCMY</td>\n",
              "      <td>Me &amp;amp; The Big Homie meanboy3000 #MEANBOY #M...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E3303EME</td>\n",
              "      <td>I'm 100% thinking of devoting my career to pro...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M4IVFSMS</td>\n",
              "      <td>#whatcausesautism VACCINES, DO NOT VACCINATE Y...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1DR6ROZ4</td>\n",
              "      <td>I mean if they immunize my kid with something ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J77ENIIE</td>\n",
              "      <td>Thanks to &lt;user&gt; Catch me performing at La Nui...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  ... agreement\n",
              "0  CL1KWCMY  ...       1.0\n",
              "1  E3303EME  ...       1.0\n",
              "2  M4IVFSMS  ...       1.0\n",
              "3  1DR6ROZ4  ...       1.0\n",
              "4  J77ENIIE  ...       1.0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "o-4fCKupC8Zj",
        "outputId": "18fb5902-2b3b-43f9-94e7-4289dab36653"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>safe_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00BHHHP1</td>\n",
              "      <td>&lt;user&gt; &lt;user&gt; ... &amp;amp; 4 a vaccine given 2 he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00UNMD0E</td>\n",
              "      <td>Students starting school without whooping coug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01AXPTJF</td>\n",
              "      <td>I'm kinda over every ep of &lt;user&gt; being \"rippe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01HOEQJW</td>\n",
              "      <td>How many innocent children die for lack of vac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01JUKMAO</td>\n",
              "      <td>CDC eyeing bird flu vaccine for humans, though...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id                                          safe_text\n",
              "0  00BHHHP1  <user> <user> ... &amp; 4 a vaccine given 2 he...\n",
              "1  00UNMD0E  Students starting school without whooping coug...\n",
              "2  01AXPTJF  I'm kinda over every ep of <user> being \"rippe...\n",
              "3  01HOEQJW  How many innocent children die for lack of vac...\n",
              "4  01JUKMAO  CDC eyeing bird flu vaccine for humans, though..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txtFwrJ5C8Zk",
        "outputId": "0d04b619-f87e-4de7-c922-7380a243b082"
      },
      "source": [
        "train['label'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.000000    4908\n",
              " 1.000000    4053\n",
              "-1.000000    1038\n",
              " 0.666667       1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVH6nE6jC8Zk"
      },
      "source": [
        "## 2. Cleaning Data\n",
        "- ensure it is a string\n",
        "- convert capital letters to small letters\n",
        "- remove characters and replace with space\n",
        "- remove punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qtSNXgeC8Zm"
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(str)\n",
        "test['safe_text'] = test['safe_text'].apply(str)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKr5F7tHC8Zn"
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(str.lower)\n",
        "test['safe_text'] = test['safe_text'].apply(str.lower)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkjYXP-2C8Zn"
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('&amp;', ' '))\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('&amp;', ' '))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-jd65rvC8Zn"
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('<user>', ' '))\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('<user>', ' '))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9xgk0lRC8Zn"
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('<url>', ' '))\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('<url>', ' '))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZnfkkQnC8Zo"
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.replace('#', ' '))\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.replace('#', ' '))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTKdG30hC8Zo"
      },
      "source": [
        "train['safe_text'] = train['safe_text'].apply(lambda x: x.strip('.').strip())\n",
        "test['safe_text'] = test['safe_text'].apply(lambda x: x.strip('.').strip())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arSNa3tQC8Zo"
      },
      "source": [
        "we only have one row with label 0.6667 and no agreement, so we would be dropping the row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CMOGpO_C8Zo"
      },
      "source": [
        "train.drop(index=[4798, 4799], inplace=True)\n",
        "train.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "d_SkRqqDC8Zp",
        "outputId": "a61fc0b2-8d3c-4c0e-f04d-cc6f9db8e971"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>safe_text</th>\n",
              "      <th>label</th>\n",
              "      <th>agreement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CL1KWCMY</td>\n",
              "      <td>me   the big homie meanboy3000  meanboy  mb  m...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E3303EME</td>\n",
              "      <td>i'm 100% thinking of devoting my career to pro...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M4IVFSMS</td>\n",
              "      <td>whatcausesautism vaccines, do not vaccinate yo...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1DR6ROZ4</td>\n",
              "      <td>i mean if they immunize my kid with something ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J77ENIIE</td>\n",
              "      <td>thanks to   catch me performing at la nuit nyc...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  ... agreement\n",
              "0  CL1KWCMY  ...       1.0\n",
              "1  E3303EME  ...       1.0\n",
              "2  M4IVFSMS  ...       1.0\n",
              "3  1DR6ROZ4  ...       1.0\n",
              "4  J77ENIIE  ...       1.0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1FFFNKnC8Zp"
      },
      "source": [
        "# max number of words in each sentence\n",
        "SEQUENCE_LENGTH = 50\n",
        "EMBEDDING_SIZE = 100\n",
        "# number of words to use, discarding the rest\n",
        "N_WORDS = 10000\n",
        "# out of vocabulary token\n",
        "OOV_TOKEN = \"<unk>\"\n",
        "padding_type = 'post'\n",
        "trunc_type = 'post'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY5yKf2MC8Zp"
      },
      "source": [
        "## 3. Preprocessing Data\n",
        "Check Out this Link to Learn More About the steps Below\n",
        "https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_33jkf7C8Zq"
      },
      "source": [
        "- Our Labels are within -1 to 1, it should not be less than 1, so we + 1 \n",
        "- Convert Labels for a multi classification task using to categorical\n",
        "- split our data\n",
        "- We Instantiate our tokenizer class to tokenize training data text\n",
        "- we pad our tokenized text to ensure  equal lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1tbMuyNC8Zq",
        "outputId": "0ad3a271-d8d8-4f95-fe50-c65754ad8648"
      },
      "source": [
        "train['label'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.0    4908\n",
              " 1.0    4053\n",
              "-1.0    1038\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w4kHZp3C8Zq"
      },
      "source": [
        "X = train['safe_text']\n",
        "y = to_categorical(train['label']+1,num_classes=3)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpdwm2s_C8Zq"
      },
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQF0c7m6C8Zq",
        "outputId": "1951a5ce-014e-4a25-85d9-d33045da470a"
      },
      "source": [
        "print('The Shape of Xraining ',X_train.shape)\n",
        "print('The Shape of Validation',X_val.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Shape of Xraining  (7999,)\n",
            "The Shape of Validation (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ_tZz7eC8Zr"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=N_WORDS, oov_token=OOV_TOKEN)\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZg5Pr5jC8Zr"
      },
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo6D6J_HC8Zr",
        "outputId": "34541229-0c6f-4f74-d145-a039a54166d4"
      },
      "source": [
        "print(\"THe first word Index are: \")\n",
        "for x in list(word_index)[0:15]:\n",
        "    print (\" {},  {} \".format(x,  word_index[x]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "THe first word Index are: \n",
            " <unk>,  1 \n",
            " the,  2 \n",
            " to,  3 \n",
            " measles,  4 \n",
            " a,  5 \n",
            " of,  6 \n",
            " in,  7 \n",
            " and,  8 \n",
            " i,  9 \n",
            " vaccine,  10 \n",
            " is,  11 \n",
            " for,  12 \n",
            " vaccines,  13 \n",
            " kids,  14 \n",
            " you,  15 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caY-WV-oC8Zr"
      },
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=SEQUENCE_LENGTH, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdGyZrpjC8Zs",
        "outputId": "361af8e3-f756-4e59-bdc9-ae06e2a69134"
      },
      "source": [
        "print(train.safe_text[1])\n",
        "print(training_sequences[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i'm 100% thinking of devoting my career to proving autism isn't caused by vaccines due to the idiotic posts i've seen about world autism day\n",
            "[18, 148, 171, 28, 126, 27, 13, 140, 49, 150, 11, 197, 32, 5, 932, 795, 1882, 150, 11, 5664]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb6ZKrEQC8Zs"
      },
      "source": [
        "test['safe_text'] = test['safe_text'].astype(str)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9caXx2BC8Zs"
      },
      "source": [
        "val_sequences = tokenizer.texts_to_sequences(X_val)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=SEQUENCE_LENGTH, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daHIPFTuC8Zt"
      },
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(test['safe_text'])\n",
        "test_padded = pad_sequences(test_sequences, maxlen=SEQUENCE_LENGTH, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwXX0YGC8Zt",
        "outputId": "6dc41a14-5619-4a73-fa9a-74c8ceaf2126"
      },
      "source": [
        "train.isnull().any()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_id     False\n",
              "safe_text    False\n",
              "label        False\n",
              "agreement    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPA0F8A2C8Zt"
      },
      "source": [
        "# 4. Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGi943JVC8Zt"
      },
      "source": [
        "Our four layers are an embedding layer, our LSTM, and two linear layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJJ3BlQoC8Zu"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(N_WORDS, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(14, activation='relu'),\n",
        "    tf.keras.layers.Dense(3,activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer=optimizer)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU_Xj96RC8Zu",
        "outputId": "7e6fc719-9390-4a5a-806b-8592a4ceb92b"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "num_epochs = 1\n",
        "history = model.fit(training_padded, y_train, epochs=num_epochs, validation_data=(val_padded, y_val))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 7s 20ms/step - loss: 0.4947 - val_loss: 0.4100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LymRwlSPC8Zu"
      },
      "source": [
        "pred = model.predict(test_padded)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1X-QM_XC8Zu",
        "outputId": "9cc24aa2-f5b5-46a4-8d09-44ad60338f6d"
      },
      "source": [
        "pred"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35070682, 0.46285847, 0.4277427 ],\n",
              "       [0.09110484, 0.17956445, 0.698197  ],\n",
              "       [0.07381827, 0.72601336, 0.23211257],\n",
              "       ...,\n",
              "       [0.2325881 , 0.41443717, 0.42840785],\n",
              "       [0.07699373, 0.14703174, 0.73255193],\n",
              "       [0.34249035, 0.45593917, 0.4201953 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCE0cPpeC8Zv"
      },
      "source": [
        "# Important Information\n",
        "\n",
        "we can go ahead and do `test['label'] = np.argmax(pred,axis=1)` for a normal multi classification task, with classification metrics  `accuracy`, but the metric given for the challenge is a root mean squared error metrics hence performance on leaderboard would be bad, so we preprocess our predictions to have values between -1 and 1, better preprocessing can be done to improve scores on leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR9tNcBUC8Zv"
      },
      "source": [
        "def process_prediction(preds):\n",
        "  r'''\n",
        "    This function helps us go from a classifiaction\n",
        "    problem to a regression one.\n",
        "    The regression values range are in [-1, 1].\n",
        "  '''\n",
        "\n",
        "  final_preds = []\n",
        "  for pred in preds:\n",
        "    argmax = np.argmax(pred, axis=0)\n",
        "    if argmax == 0: final_preds.append( -1*pred[0] )\n",
        "    elif argmax == 1: final_preds.append( 0 )\n",
        "    else: final_preds.append( pred[2] )\n",
        "    \n",
        "  return final_preds\n",
        "\n",
        "\n",
        "def rmse(true, pred):\n",
        "  return np.sqrt(mean_squared_error(true, pred))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A56Vw-FpC8Zv"
      },
      "source": [
        "predictions = process_prediction(pred)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-hg8ePeC8Zv"
      },
      "source": [
        "test['label'] = predictions"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "Fh0pLpWjC8Zv",
        "outputId": "e1951603-4ff5-4697-8f9a-9ac1a7f96119"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>safe_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00BHHHP1</td>\n",
              "      <td>...   4 a vaccine given 2 healthy peeps, fda t...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00UNMD0E</td>\n",
              "      <td>students starting school without whooping coug...</td>\n",
              "      <td>0.698197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01AXPTJF</td>\n",
              "      <td>i'm kinda over every ep of   being \"ripped fro...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01HOEQJW</td>\n",
              "      <td>how many innocent children die for lack of vac...</td>\n",
              "      <td>0.702510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01JUKMAO</td>\n",
              "      <td>cdc eyeing bird flu vaccine for humans, though...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id                                          safe_text     label\n",
              "0  00BHHHP1  ...   4 a vaccine given 2 healthy peeps, fda t...  0.000000\n",
              "1  00UNMD0E  students starting school without whooping coug...  0.698197\n",
              "2  01AXPTJF  i'm kinda over every ep of   being \"ripped fro...  0.000000\n",
              "3  01HOEQJW  how many innocent children die for lack of vac...  0.702510\n",
              "4  01JUKMAO  cdc eyeing bird flu vaccine for humans, though...  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1dkO_2AC8Zw"
      },
      "source": [
        "test[['tweet_id','label']].to_csv('submissions.csv',index=False)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39-ErpJ_C8Zw"
      },
      "source": [
        "## Some useful Insights\n",
        "- The Text Cleaning done here is vanilla, you can do a lot them\n",
        "- use a pretrained word embeddings e.g **Glove** \n",
        "- Try out the Transformer Architecture, or Use a Pretrained Transformer Architecture\n",
        "- Tweak Neural Network Parameters\n",
        "- increase no of epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSOxzw7oC8Zw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}